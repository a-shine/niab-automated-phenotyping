\section{Introduction}\label{sec:introduction}

\subsection{Context and motivation}\label{subsec:context-n-motivation}
% Phenotyping and breeding for food security and the environment
Global agriculture faces significant challenges in ensuring food security for a large population in a changing climate~\cite{furbankPhenomicsTechnologiesRelieve2011}. 
Breeders must quickly develop high-yielding crop lines that are more resilient to water strain, extreme heat, pests, and weeds.
A crop's physical characteristics and attributes are known as the phenotype and are determined by the plant's genotype~\cite{braytonPhenotyping2018}.
These characteristics determine the plant's resilience and ability to thrive.

% Shoot phenotyping for out-competing weeds in the context of tef (manually sowed, smallholder farms)
We need to develop resistant crops to sustain the food supply in East Africa, as global warming causes both waterlogging and drought. 
Tef (Eragrostis tef) is an orphan cereal crop from the region. 
The closest cultivated relative is finger millet (Eleucine coracana).
It is a type of grass well adapted to Ethiopian conditions and holds a high percentage of proteins and micronutrients (e.g., calcium, iron, and zinc).
It is an important core food~\cite{redaAchievingFoodSecurity2014, tadeleEmpiricalReviewUse2021}.

Furthermore, Tef is typically grown by smallholder farmers with limited access to machinery and crop protection.
The seeds are often sown by hand, resulting in the crops being dispersed chaotically when germinating.
This means mechanical weeding can be very challenging.
Therefore, it would be beneficial to develop breed lines that can cover the ground faster (large amounts of above-ground plant biomass).
These lines would suppress weed growth by out-competing weeds for light.

% Introduce phenotyping bottleneck problem with high throughput technique
There are several approaches to plant breeding.
A method which requires a deep understanding of the plant genotype-to-phenotype mapping, where genes are precisely edited to achieve the desired phenotypic traits.
Another approach is a high-throughput technique where a high volume of lines is created by exposing seeds to a mutation-inducing agent, increasing the probability that one of the mutated seeds will exhibit the desired phenotypic properties.
The seeds are grown, and each resulting individual is analysed to determine whether the characteristics have been achieved.
The latter approach introduces a new problem in quantitative plant science: designing automated pipelines to process the large volumes of rich data generated by the phenotyping apparatus~\cite{furbankPhenomicsTechnologiesRelieve2011, grosskinskyPlantPhenomicsNeed2015, houlePhenomicsNextChallenge2010}.
Computer vision and Deep Learning (DL) are utilised to develop semi- or fully-automated image processing pipelines.

Image-based high-throughput plant phenotyping aims to associate the characteristics of plants as observed in images to their genotype, known as phenotype-to-genotype mapping~\cite{liReviewImagingTechniques2014}. 
In order for the technique to be viable, we need to make evaluating plant characteristics as efficient and scalable as genetic screening, alleviating the data analysis bottleneck~\cite{millerComputerVisionAnalysis2007, fahlgrenLightsCameraAction2015}.

\subsection{Previous work}\label{subsec:previous-work}

% Basically a paragraph per IMPORTANT paper (eventually try and weave ideas together i.e. these guys did root phenotyping, while there did shoot phenotyping both used RGB imagery and developed initial semantic segmentation masks)

% What type of phenotyping shoot or root
% What ML models do they use + what computer vision/trad algorithm do they use to process the imagery
% What level of performance do they achieve/their conclusion

% What do they have in common? (using RGB imagery, DL for semantic segmentation, 'easy' to use for practitioners)
Previous work has been carried out on image-based, high-throughput plant phenotyping for both shoots and roots~\cite{bodnerRGBSpectralRoot2017, chaudhuryComputerVisionBased2015, chaudhuryMachineVisionSystem2019, clarkThreeDimensionalRootPhenotyping2011, daschoudhuryHolisticComponentPlant2018, fahlgrenLightsCameraAction2015, fanSegmentationGuidedDeepLearning2022, guoIlluminationInvariantSegmentation2013, guoEasyPCCBenchmarkDatasets2017, henkeSemiAutomatedGroundTruth2021, hutherARADEEPOPSISAutomatedWorkflow2020, leeAutomatedHighthroughputPlant2018, liReviewImagingTechniques2014, luoEff3DPSeg3DOrganLevel2023, muhlichMeasuringPlantRoot2008, narisettiDeepLearningBased2022, smithSegmentationRootsSoil2020, yatesNewImagingMachinelearning2021}.
While some works focus on root phenotyping~\cite{bodnerRGBSpectralRoot2017, clarkThreeDimensionalRootPhenotyping2011, muhlichMeasuringPlantRoot2008, smithSegmentationRootsSoil2020}, others develop tools and methods for shoot phenotyping~\cite{chaudhuryComputerVisionBased2015, chaudhuryMachineVisionSystem2019, daschoudhuryHolisticComponentPlant2018, fanSegmentationGuidedDeepLearning2022, guoIlluminationInvariantSegmentation2013, guoEasyPCCBenchmarkDatasets2017, henkeSemiAutomatedGroundTruth2021, hutherARADEEPOPSISAutomatedWorkflow2020, leeAutomatedHighthroughputPlant2018, luoEff3DPSeg3DOrganLevel2023, narisettiDeepLearningBased2022}.
Many of the pipelines developed use a single (or time-series collection) of RGB (Red, Green and Blue) imagery, although some look at other hyperspectral imagery, notably for studying roots as they are more visible under UV light~\cite{bodnerRGBSpectralRoot2017, wassonPortableFluorescenceSpectroscopy2016}.
Some experimental setups use camera arrays or robotic manipulation of a single camera to capture several angles and observe characteristics that can only be measured in three dimensions~\cite{chaudhuryComputerVisionBased2015, chaudhuryMachineVisionSystem2019, clarkThreeDimensionalRootPhenotyping2011}.

A common step across the image processing pipelines is semantic segmentation of the shoot or root from imagery.
This allows for further processing to determine phenotypic characteristics such as root length, root width, root or shoot branching factor, leaf count and shoot area.
Segmentation tends to be semantic, so the image is divided into several segments for detected objects, but there is no distinction between different instances of the same object.
Traditional computer vision segmentation techniques include HSV (Hue Saturation Value) thresholds, which classify whether or not pixels belong to an object by determining bounds for Hue Saturation values~\cite{adamsPlantSegmentationSupervised2020}.
However, more recent papers opt for a DL approach over traditional non-ML approaches due to the optical variability in plant appearances~\cite{narisettiDeepLearningBased2022}.
For shoot segmentation, the U-Net architecture~\cite{ronnebergerUNetConvolutionalNetworks2015} is commonly used due to its simple implementation and effectiveness~\cite{narisettiDeepLearningBased2022, whiteGeneratingSegmentationMasks2020}.
In addition, several off-the-shelf models for root and shoot segmentation, such as DeepShoot~\cite{narisettiDeepLearningBased2022} and Root Painter~\cite{smithOotAinterDeep2022} are available, so others can more easily build segmentation into their pipelines.

% (i.e. these papers all do shoot phenotyping, one looking at multiple individuals, in greenhouse, in fields...)
Of the papers focused on shoot phenotyping, several have developed image processing pipelines for top-down imagery~\cite{fanSegmentationGuidedDeepLearning2022, guoIlluminationInvariantSegmentation2013, ronnebergerUNetConvolutionalNetworks2015, hutherARADEEPOPSISAutomatedWorkflow2020, leeAutomatedHighthroughputPlant2018, narisettiDeepLearningBased2022} and side-on imagery~\cite{daschoudhuryHolisticComponentPlant2018, narisettiDeepLearningBased2022}. 
For use in high-throughput phenotyping, the data inferred from an image must be associated with an individual genotype, so images usually contain a single individual.
However, \textit{Lee et al.}~\cite{leeAutomatedHighthroughputPlant2018} have developed a phenotyping platform with several trays of individuals and a camera on two motor-controlled axes.
The camera moves from tray to tray to take regular images from above throughout the plant growth cycle.
While most phenotyping platforms are setup in labs or greenhouses in order to better control lighting and protect apparatus such as cameras for capturing images, \textit{Guo et al.}~\cite{guoIlluminationInvariantSegmentation2013, guoEasyPCCBenchmarkDatasets2017} capture image data on phenotyping platform in open field environments.
This has the advantage of measuring crop properties in a more natural environment, where crops are exposed to natural conditions and soil.
In addition, crops seldom grow in isolated environments, and their development can be impacted by interaction with neighbouring individuals~\cite{finchWheatRootLength2017}, so monitoring the individual genotype behaviours in a multi-crop environment is important.
A notable limitation of taking imagery in open field conditions is wind can move the shoots and leaves, causing segmentation to fail and making identification of individuals very difficult, which limits its use case for phenotype-to-genotype mapping~\cite{guoEasyPCCBenchmarkDatasets2017}.

The development of image-based, high-throughput plant phenotyping pipelines is an interdisciplinary effort between plant science and engineering for designing the phenotyping platform, as well as computer science for image processing involving computer vision and ML.
In previous work, while the developed processing technique is coupled to particular phenotyping and imaging platforms, some have attempted to make parts of the pipeline available for use by others~\cite{hutherARADEEPOPSISAutomatedWorkflow2020, henkeSemiAutomatedGroundTruth2021, guoEasyPCCBenchmarkDatasets2017, narisettiDeepLearningBased2022}.
Moving forward, a clear priority is developing tooling that can be re-used between different platforms and by plant scientists without the need for a Computer vision or ML background.
\textit{Narisetti et al.}~\cite{narisettiDeepLearningBased2022}, and \textit{Smith et al.}~\cite{smithSegmentationRootsSoil2020}, put forward a Graphical User Interface (GUI) software that allows practitioners to segment out the shoots or roots respectively for several common crop varieties.

% Introduce the notion of logic-based (graphs) for post-processing images once segmented and plotting temporal evolution of crop development
In \textit{Muhlich et al.}'s~\cite{muhlichMeasuringPlantRoot2008} on measuring plant root growth and development, the plants are grown in a transparent growth medium, allowing for easy, non-invasive imagery of the plant root system.
The team uses nonlinear filters to isolate the roots and then a graph-based approach to follow each of the roots.
There is the notable problem of distinguishing between when root branches into sub-roots or two independent roots crossing.
They use traditional logic-based techniques to classify root crossings and branches.
Once they are able to identify each of the primary roots and branches, they integrate temporal information and plot the growth of the complete root system as well as the contribution of different root orders over time.
Like \textit{Muhlich et al.}'s~\cite{muhlichMeasuringPlantRoot2008}, \textit{Choudhury et al.}~\cite{daschoudhuryHolisticComponentPlant2018} use 2D imagery, temporal image sequences and a graph-based approach to monitor crop development, in their case maize plants, focusing on the above ground numbers of leaves and the individual leaf growth.
In addition to developing novel computer vision algorithms for automated detection of individual leaves and the stem they have also made a publicly available benchmark dataset of side on plant images.

% Discuss PCCr and other phenotypic metrics determined from image pipelines
\textit{Gui et al.}~\cite{guoEasyPCCBenchmarkDatasets2017} developed a tool for high throughput measurements of the plant canopy coverage ratio under field conditions.
They choose to develop an image proceeding pipeline that measures the plant canopy coverage ratio (PCCr) as it is a good indicator of plant growth status and correlates with the leaf area index, canopy light interception, nitrogen content, and crop yield~\cite{campilloUsingDigitalImages2008, casadesusUsingVegetationIndices2007}.
In addition, it is a good metric to measure from top-down imagery as it is deﬁned as "the percentage of the orthogonal projection area relative to the area of crop foliage in the horizontal plane"~\cite{guoEasyPCCBenchmarkDatasets2017}.

% Main limitation of previous techniques (not adaptable, often not phenotyping with neighbouring plants - plants interacting between each other (\cite{finchWheatRootLength2017}))
An overarching limitation of the previous work is that the image processing pipeline is tightly coupled to the experimental procedure/design, limiting the generalizability of the technique despite general parts of the pipelines being generally applicable, such as the root segmentation model.
When using non-ML segmentation different experimental setups and camera placements represent a major obstacle in the efficient and accurate processing and analysis of large volumes of image data~\cite{minerviniImageAnalysisNew2015}.
In addition, many of the phenotyping platforms, particuallty setup on lab environments only have one crop per pot.
While this makes image analysis easier it would be beneficial to observe plants growing in communities~\cite{finchWheatRootLength2017} while still being able to map an individual to it's genotype.

\subsection{Research aims}\label{subsec:research-aims} % Overarching aim and specific research questions

Being able to track single plants growing alongside neighbours is paramount to the selection of new crop varieties that are resilient against weeds and well adapted to co-cultivating conditions. The project addresses developing an image-analysis-based method that would allow assessment of the development of the canopy over time, using images acquired in testing a plant's 45 mutant population. In this project, we focus on working the Tef, a popular crop in Ethiopia.

We will track the development of young shoots as they germinate to determine which shoots develop fastest and, hence, can outcompete weeds during the most vulnerable period of the crop's lifecycle for weed-related issues.

In the process, we will evaluate the feasibility of image-based, high-throughput plant phenotyping of shoots from top-down imagery on the NIAB dataset. We will explore, unlike previous work, how an image-based processing pipeline can be retrofitted to an existing dataset rather than designing a phenotyping platform specifically with an image-processing pipeline in mind.

As part of the project, we will develop a robust semantic segmentation ML model for young Tef shoots. We will determine which model architectures perform best, how annotation quality affects model performance, and how to deal with low annotation budgets with an active learning approach. Like previous work~\cite{smithOotAinterDeep2022, narisettiDeepLearningBased2022}, we will make the model available publicly for use in further research.

% Make a numbered list of research questions that I can refer too